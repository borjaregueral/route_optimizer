{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, LongType, TimestampType\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize AWS credentials from the .env file\n",
    "AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "AWS_SESSION_TOKEN = os.getenv('AWS_SESSION_TOKEN')\n",
    "AWS_REGION = os.getenv('AWS_REGION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/borja/Library/Caches/pypoetry/virtualenvs/route-optimizer-AqO2e-Ud-py3.11/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/borja/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/borja/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7f5eb7e1-b885-4843-9ef8-a45e0f5de892;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.4.0 in central\n",
      "\tfound io.delta#delta-storage;2.4.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.1026 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 541ms :: artifacts dl 18ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.1026 from central in [default]\n",
      "\tio.delta#delta-core_2.12;2.4.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.4.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.2 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   6   |   0   |   0   |   0   ||   6   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7f5eb7e1-b885-4843-9ef8-a45e0f5de892\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 6 already retrieved (0kB/16ms)\n",
      "24/10/02 04:01:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Path to your local JAR files\n",
    "local_jars = \"/Users/borja/Documents/Somniumrema/projects/de/route_optimizer/jars/aws-java-sdk-kinesis-1.12.364.jar\"\n",
    "\n",
    "# Initialize Spark session with Delta and S3 settings\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KinesisToDeltaLake\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:2.4.0,org.apache.hadoop:hadoop-aws:3.3.2,com.amazonaws:aws-java-sdk-bundle:1.11.1026\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", AWS_ACCESS_KEY_ID) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", AWS_SECRET_ACCESS_KEY) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.session.token\", AWS_SESSION_TOKEN) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"s3.amazonaws.com\") \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"134217728\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Optional: Adjust logging level\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize boto3 client for Kinesis with your credentials\n",
    "kinesis_client = boto3.client(\n",
    "    'kinesis',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    aws_session_token=AWS_SESSION_TOKEN,\n",
    "    region_name=AWS_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"total_weight\", DoubleType(), True),\n",
    "    StructField(\"total_volume\", DoubleType(), True),\n",
    "    StructField(\"total_price\", DoubleType(), True),\n",
    "    StructField(\"order_timestamp\", TimestampType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"lat\", DoubleType(), True),\n",
    "    StructField(\"lon\", DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the timestamps to proper datetime objects\n",
    "def convert_timestamps(orders):\n",
    "    for order in orders:\n",
    "        if isinstance(order['order_timestamp'], str):\n",
    "            # Only convert if the timestamp is a string\n",
    "            order['order_timestamp'] = datetime.strptime(order['order_timestamp'], '%Y-%m-%d %H:%M:%S')\n",
    "    return orders\n",
    "\n",
    "# Function to convert the location field from MapType to StructType\n",
    "def transform_location(order):\n",
    "    if isinstance(order['location'], dict):\n",
    "        location_data = order['location']\n",
    "        order['location'] = {\n",
    "            \"address\": location_data['address'],\n",
    "            \"lat\": float(location_data['lat']),\n",
    "            \"lon\": float(location_data['lon'])\n",
    "        }\n",
    "    return order\n",
    "\n",
    "# Function to get the shard iterator\n",
    "def get_shard_iterator(stream_name, shard_id):\n",
    "    response = kinesis_client.get_shard_iterator(\n",
    "        StreamName=stream_name,\n",
    "        ShardId=shard_id,\n",
    "        ShardIteratorType='LATEST'  # or 'LATEST' for new records\n",
    "    )\n",
    "    return response['ShardIterator']\n",
    "\n",
    "# Function to read records from the Kinesis stream\n",
    "def read_kinesis_records(stream_name, shard_iterator):\n",
    "    while True:\n",
    "        response = kinesis_client.get_records(ShardIterator=shard_iterator, Limit=100)\n",
    "        records = response['Records']\n",
    "        for record in records:\n",
    "            # No need to base64 decode, just parse the data directly\n",
    "            order_data = record['Data']\n",
    "            order = json.loads(order_data)\n",
    "            print(\"Received order:\", order)\n",
    "\n",
    "        # Update the shard iterator for the next batch of records\n",
    "        shard_iterator = response['NextShardIterator']\n",
    "\n",
    "        # Sleep to avoid hitting API rate limits\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulated order: {'order_id': '140680f5-cbf9-4056-922e-2ff935a078f2', 'customer_id': 'cus-ba8d32e6-6f9c-4ddb-a0a0-bdc936739fbb', 'total_weight': 82.73160870030328, 'total_volume': 318.9174240318443, 'total_price': 412.70773183574084, 'order_timestamp': '2024-10-02 04:01:42', 'status': 'RECEIVED', 'lat': 40.5202115180548, 'lon': -3.8638075430981003}\n",
      "Threshold met: Dispatching 1 orders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/02 04:01:47 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "24/10/02 04:02:07 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 orders to Delta table.\n",
      "Accumulated order: {'order_id': 'b26faf91-8581-47c5-8a7a-bcab8ef664a9', 'customer_id': 'cus-bbf84676-a48e-4beb-8758-22a8bbcdbd03', 'total_weight': 38.75207275621183, 'total_volume': 270.4332401055019, 'total_price': 36.17281916219022, 'order_timestamp': '2024-10-02 04:02:29', 'status': 'RECEIVED', 'lat': 40.37381234111349, 'lon': -3.6619045311504714}\n",
      "Threshold met: Dispatching 1 orders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 orders to Delta table.\n",
      "Accumulated order: {'order_id': 'ae7715ce-7714-4d2e-8beb-6e4e69e3ca72', 'customer_id': 'cus-99e1c03c-9e4d-4a38-92b4-34819d8a1909', 'total_weight': 48.12950760579068, 'total_volume': 460.40128508892, 'total_price': 928.9953000140409, 'order_timestamp': '2024-10-02 04:03:00', 'status': 'RECEIVED', 'lat': 40.55352027399454, 'lon': -3.846850240184429}\n",
      "Threshold met: Dispatching 1 orders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 orders to Delta table.\n",
      "Accumulated order: {'order_id': '6ba61fa1-8590-4e43-a3d5-440268d80b52', 'customer_id': 'cus-e54fd919-0cd3-40e3-801b-3aa4f0015c6a', 'total_weight': 43.53990041187081, 'total_volume': 139.95677803342312, 'total_price': 420.68691285213123, 'order_timestamp': '2024-10-02 04:03:43', 'status': 'RECEIVED', 'lat': 40.56735698592657, 'lon': -3.7339000542917575}\n",
      "Threshold met: Dispatching 1 orders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 orders to Delta table.\n",
      "Accumulated order: {'order_id': '9b442566-8a8b-4081-b6fd-87ff8cb1be2e', 'customer_id': 'cus-012169ba-74fe-44ad-b7f7-48923011499a', 'total_weight': 48.73753836832661, 'total_volume': 242.98560297383696, 'total_price': 572.0745375784338, 'order_timestamp': '2024-10-02 04:04:22', 'status': 'RECEIVED', 'lat': 40.41326882171988, 'lon': -3.7854324815045137}\n",
      "Threshold met: Dispatching 1 orders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 orders to Delta table.\n",
      "Accumulated order: {'order_id': '64bd7522-0a7f-44e0-a79f-450a554fb25b', 'customer_id': 'cus-5c6fc123-cf6a-41f8-9ce3-a9d80ddceaa8', 'total_weight': 90.67317748547849, 'total_volume': 375.40339945429565, 'total_price': 291.02050389950824, 'order_timestamp': '2024-10-02 04:04:45', 'status': 'RECEIVED', 'lat': 40.64060844221572, 'lon': -3.7070802941843075}\n",
      "Threshold met: Dispatching 1 orders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 orders to Delta table.\n",
      "Accumulated order: {'order_id': '0562e23b-c8c5-41d8-9312-e1e7afa0898d', 'customer_id': 'cus-4b7057d8-c3dd-4449-b4dc-5f4c15a4bdb6', 'total_weight': 46.74087426850831, 'total_volume': 392.79371443806525, 'total_price': 312.49896608574, 'order_timestamp': '2024-10-02 04:04:56', 'status': 'RECEIVED', 'lat': 40.570276017311635, 'lon': -3.632292221828427}\n",
      "Threshold met: Dispatching 1 orders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 orders to Delta table.\n",
      "Accumulated order: {'order_id': '8d6adae1-e68d-4e59-aeef-5eb0c1c6227f', 'customer_id': 'cus-49f84bcc-69f8-4be7-94ef-17a0a2d80f2c', 'total_weight': 92.60351507581612, 'total_volume': 242.4883615375743, 'total_price': 880.1691661195565, 'order_timestamp': '2024-10-02 04:05:29', 'status': 'RECEIVED', 'lat': 40.58116490703484, 'lon': -3.7770963729789564}\n",
      "Threshold met: Dispatching 1 orders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 orders to Delta table.\n",
      "Accumulated order: {'order_id': '4b940677-dd12-4e2c-9613-0fe1a7aa1760', 'customer_id': 'cus-1a53dfa5-de42-4e91-aa67-7dfd3e07e22d', 'total_weight': 52.89003629329177, 'total_volume': 46.821241954089196, 'total_price': 879.0783040278777, 'order_timestamp': '2024-10-02 04:06:11', 'status': 'RECEIVED', 'lat': 40.529752244413984, 'lon': -3.7012124227966563}\n",
      "Threshold met: Dispatching 1 orders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 orders to Delta table.\n",
      "Accumulated order: {'order_id': '20a04e22-5f52-4acd-b582-ac9bf35574a6', 'customer_id': 'cus-ce1c21be-f175-4b09-b23e-416dcd687ae5', 'total_weight': 97.50866167890928, 'total_volume': 91.49363948872059, 'total_price': 943.7143782517655, 'order_timestamp': '2024-10-02 04:06:41', 'status': 'RECEIVED', 'lat': 40.59678718920532, 'lon': -3.777971327149063}\n",
      "Threshold met: Dispatching 1 orders.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1 orders to Delta table.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m shard_iterator \u001b[38;5;241m=\u001b[39m get_shard_iterator(stream_name, shard_id)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Start the dispatcher\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[43mdispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 57\u001b[0m, in \u001b[0;36mdispatcher\u001b[0;34m(shard_iterator)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Update shard iterator for the next batch\u001b[39;00m\n\u001b[1;32m     56\u001b[0m shard_iterator \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNextShardIterator\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 57\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Initialize buffer, limits, and thresholds\n",
    "order_buffer = []\n",
    "weight_threshold = 15  # Example weight threshold (can be adjusted)\n",
    "volume_threshold = 500  # Example volume threshold (can be adjusted)\n",
    "time_threshold = 60 * 30 # Example time threshold (e.g., 30 minutes)\n",
    "buffer_limit = 1000       # Optional, max number of orders in the buffer\n",
    "last_flush_time = time.time()\n",
    "\n",
    "# S3 path for Delta table\n",
    "delta_table_path = \"s3a://orders-for-dispatch/dispatching\"\n",
    "\n",
    "# Dispatcher function to read Kinesis records, accumulate, and process them\n",
    "def dispatcher(shard_iterator):\n",
    "    global order_buffer, last_flush_time\n",
    "\n",
    "    while True:\n",
    "        # Fetch records from Kinesis using shard_iterator\n",
    "        response = kinesis_client.get_records(ShardIterator=shard_iterator)\n",
    "        records = response['Records']\n",
    "\n",
    "        # Parse and accumulate orders\n",
    "        for record in records:\n",
    "            order_data = json.loads(record['Data'])\n",
    "            order_buffer.append(order_data)\n",
    "            print(f\"Accumulated order: {order_data}\")\n",
    "\n",
    "        # Convert timestamps if necessary\n",
    "        order_buffer = convert_timestamps(order_buffer)\n",
    "\n",
    "        # Calculate accumulated weight and volume\n",
    "        total_weight = sum(order['total_weight'] for order in order_buffer)\n",
    "        total_volume = sum(order['total_volume'] for order in order_buffer)\n",
    "        time_elapsed = time.time() - last_flush_time\n",
    "\n",
    "        # Check if any thresholds are met (weight, volume, or time)\n",
    "        if total_weight >= weight_threshold or total_volume >= volume_threshold or time_elapsed >= time_threshold:\n",
    "            print(f\"Threshold met: Dispatching {len(order_buffer)} orders.\")\n",
    "            \n",
    "            # Update the status of all orders to 'DISPATCH_READY'\n",
    "            for order in order_buffer:\n",
    "                order['status'] = 'READY_FOR_DISPATCH'\n",
    "\n",
    "            # Convert buffer to DataFrame and write to Delta table\n",
    "            df = spark.createDataFrame(order_buffer, schema=schema)\n",
    "            df.write.format(\"delta\").mode(\"append\").save(delta_table_path)\n",
    "            print(f\"Saved {len(order_buffer)} orders to Delta table.\")\n",
    "            \n",
    "            # Clear the buffer and reset flush time\n",
    "            order_buffer.clear()\n",
    "            last_flush_time = time.time()\n",
    "\n",
    "        # Update shard iterator for the next batch\n",
    "        shard_iterator = response['NextShardIterator']\n",
    "        time.sleep(2)  # Sleep to avoid rate limits\n",
    "\n",
    "# Get the shard iterator\n",
    "stream_name = 'OrderStreamForDispatching'  # Replace with your stream name\n",
    "shard_id = 'shardId-000000000000'  # Get the shard ID from the stream's details\n",
    "shard_iterator = get_shard_iterator(stream_name, shard_id)\n",
    "\n",
    "# Start the dispatcher\n",
    "dispatcher(shard_iterator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "route-optimizer-AqO2e-Ud-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
